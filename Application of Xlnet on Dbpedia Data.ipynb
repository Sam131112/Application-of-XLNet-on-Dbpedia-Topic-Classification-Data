{"cells":[{"metadata":{"id":"4v8ojg_lon1d","outputId":"ac2a1f4d-f1e6-41a2-e784-1dd68ea91bab","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/dbpedia-classes/DBPEDIA_train.csv\n/kaggle/input/dbpedia-classes/DBPEDIA_test.csv\n/kaggle/input/dbpedia-classes/DBPEDIA_val.csv\n/kaggle/input/dbpedia-classes/DBP_wiki_data.csv\n","name":"stdout"}]},{"metadata":{"id":"UkM2q_PDo_2R","outputId":"3d45dd04-c491-404d-b6aa-8c393a395f7d","trusted":true},"cell_type":"code","source":"import os\nimport math\n\nimport torch\nfrom torch.nn import BCEWithLogitsLoss\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,WeightedRandomSampler\nfrom transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig,XLNetForSequenceClassification\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nimport matplotlib.pyplot as plt\nimport pickle\n%matplotlib inline","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"id":"6VK0Ie7exqeT","trusted":true},"cell_type":"code","source":"from collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score,accuracy_score","execution_count":4,"outputs":[]},{"metadata":{"id":"9LZD-6Oep3c_","trusted":true},"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","execution_count":5,"outputs":[]},{"metadata":{"id":"234H4-7dN8tc","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/dbpedia-classes/DBP_wiki_data.csv\")\n#train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dbpedia-classes/DBPEDIA_train.csv\")\n#validation = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dbpedia-classes/DBPEDIA_val.csv\")\n#test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dbpedia-classes/DBPEDIA_test.csv\")","execution_count":6,"outputs":[]},{"metadata":{"id":"aUu5eKTIv-2t","trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(data[\"l1\"])\ndata[\"target\"] = le.transform(data['l1'])","execution_count":7,"outputs":[]},{"metadata":{"id":"tui6RGeFu4QU","outputId":"4bccd6e7-f23d-44f9-c5a7-3ab7f4659d40","trusted":true},"cell_type":"code","source":"device","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"'cuda'"},"metadata":{}}]},{"metadata":{"id":"eHExeRyL0xve","trusted":true},"cell_type":"code","source":"train , test = train_test_split(data,test_size=0.25,shuffle=True,random_state=42,stratify=data[\"target\"])\ntrain , val = train_test_split(train,test_size=0.1,shuffle=True,random_state=42,stratify=train[\"target\"])","execution_count":9,"outputs":[]},{"metadata":{"id":"kNQV8nEs6m_c","outputId":"9a320871-83ea-4763-fa3a-f2263077652b","trusted":true},"cell_type":"code","source":"print(len(train),len(test),len(val))\nprint(\"Train \",Counter(train['target']))\nprint(\"Test \",Counter(test['target']))\nprint(\"Validation \",Counter(val['target']))","execution_count":10,"outputs":[{"output_type":"stream","text":"231376 85696 25709\nTrain  Counter({0: 119704, 3: 43961, 4: 21026, 8: 20137, 2: 18265, 5: 5607, 7: 1686, 6: 752, 1: 238})\nTest  Counter({0: 44336, 3: 16282, 4: 7787, 8: 7458, 2: 6765, 5: 2077, 7: 624, 6: 279, 1: 88})\nValidation  Counter({0: 13301, 3: 4885, 4: 2336, 8: 2237, 2: 2029, 5: 623, 7: 187, 6: 84, 1: 27})\n","name":"stdout"}]},{"metadata":{"id":"ETUebMDPkQQb","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"s5hEgwh-kra2","trusted":true},"cell_type":"code","source":"#config = XLNetConfig()\n#config.from_pretrained = 'xlnet-large-cased'\n#config.output_hidden_states = True\n#config.output_attentions = False\n#config.summary_type = 'mean'","execution_count":11,"outputs":[]},{"metadata":{"id":"8T6tTi8jG-vX","trusted":true},"cell_type":"code","source":"#tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n#model = XLNetForSequenceClassification(config)","execution_count":12,"outputs":[]},{"metadata":{"id":"PAhAruqvHDIK","trusted":true},"cell_type":"code","source":"#model.config","execution_count":13,"outputs":[]},{"metadata":{"id":"XE5NWTikOhnH","trusted":true},"cell_type":"code","source":"#Input_ids = tokenizer.encode_plus(\"Hello, my dog is cute\", add_special_tokens=True) # Batch size 1","execution_count":14,"outputs":[]},{"metadata":{"id":"z4ZWohgUOomL","trusted":true},"cell_type":"code","source":"#input_ids , atten_mask , token_type_ids, labels  = torch.tensor(Input_ids[\"input_ids\"]).unsqueeze(0), torch.tensor(Input_ids[\"attention_mask\"]).unsqueeze(0),torch.tensor(Input_ids[\"token_type_ids\"]).unsqueeze(0),torch.tensor([1]).unsqueeze(0) ","execution_count":15,"outputs":[]},{"metadata":{"id":"ysgSfxG9FtMY","trusted":true},"cell_type":"code","source":"#outputs = model(input_ids=input_ids,attention_mask=atten_mask,token_type_ids=token_type_ids,labels=labels)","execution_count":16,"outputs":[]},{"metadata":{"id":"MvIjOFTzqOrc","trusted":true},"cell_type":"code","source":"#len(outputs)","execution_count":17,"outputs":[]},{"metadata":{"id":"JNiu-xnXmPh4","trusted":true},"cell_type":"code","source":"#outputs[2][0].shape","execution_count":18,"outputs":[]},{"metadata":{"id":"HsL8pfp8hBb7"},"cell_type":"markdown","source":"# Starting Model Building From Here !"},{"metadata":{"id":"XBOf_Aixhp3Z","trusted":true},"cell_type":"code","source":"def CreateData(tokenizer,data):\n    inp_ids = []\n    tok_type_ids = []\n    atten_mask  = []\n    labels = []\n    for i in range(len(data)):\n      text = data.iloc[i][\"text\"]\n      temp = tokenizer.encode_plus(text,max_length=100,pad_to_max_length = True)\n      inp_ids.append(temp[\"input_ids\"])\n      tok_type_ids.append(temp[\"token_type_ids\"])\n      atten_mask.append(temp[\"attention_mask\"])\n      labels.append([data.iloc[i][\"target\"]])\n    \n    input_ids = torch.tensor(inp_ids,dtype=torch.long)\n    attention_mask = torch.tensor(atten_mask,dtype=torch.long)\n    token_type_ids = torch.tensor(tok_type_ids,dtype=torch.long)\n    labels = torch.tensor(labels,dtype=torch.long)\n\n    dataset = TensorDataset(input_ids, attention_mask,token_type_ids,labels)\n    return dataset","execution_count":19,"outputs":[]},{"metadata":{"id":"Vk1QyxmR1Fds","trusted":true},"cell_type":"code","source":"def make_weight(data):\n  #data = data.copy()\n  counter = Counter(data[\"target\"].values)\n  print(counter)\n  data[\"Weight\"] = data[\"target\"].apply(lambda x:counter[x])\n  data[\"Weight\"] = 1.0 / data[\"Weight\"]\n  return data","execution_count":20,"outputs":[]},{"metadata":{"id":"72UQH6Xl5Za5","trusted":false},"cell_type":"code","source":"#data_v = make_weight(train)","execution_count":0,"outputs":[]},{"metadata":{"id":"y9D86JsTNhtf"},"cell_type":"markdown","source":"## Model Building with Dev Set"},{"metadata":{"id":"qoqxSPXntOgH","trusted":true},"cell_type":"code","source":"def train_engine(train_data,val_data,model,batch_sz,lr,epochs,device):\n\n  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n  train_data = make_weight(train_data)\n  train_dataset = CreateData(tokenizer,train_data)\n  val_dataset = CreateData(tokenizer,val_data)\n  #pickle.dump(open(\"/content/drive/My Drive/Colab Notebooks/train_dataset_tokenised.p\",train_dataset))\n  #pickle.dump(open(\"/content/drive/My Drive/Colab Notebooks/val_dataset_tokenised.p\",val_dataset))\n  optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-1, correct_bias=False)\n  #scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)\n  weight_sampler = WeightedRandomSampler(weights=train_data[\"Weight\"].values,num_samples=len(train_data[\"Weight\"].values),replacement=True)\n  train_loader = DataLoader(train_dataset,batch_size=batch_sz,sampler=weight_sampler)\n  train_loss = []\n  val_loss = []\n  best_loss = math.inf\n  for epoch in range(epochs):\n    epoch_train_loss = 0\n    model.train()\n    for batch_id,batch in enumerate(train_loader):\n      if batch_id % 7000 == 0:\n          print(epoch,batch_id)\n      optimizer.zero_grad()\n      inputs = {\"input_ids\": batch[0].to(device), \"attention_mask\": batch[1].to(device),  \"token_type_ids\": batch[2].to(device),\"labels\": batch[3].to(device)}\n      #lb = inputs[\"labels\"].squeeze(1).numpy().tolist()\n      #print(Counter(lb),len(Counter(lb)))\n      loss , logits = model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'],token_type_ids=inputs['token_type_ids'],labels=inputs['labels'])\n      _ , out_preds = torch.max(logits,axis=1)\n      epoch_train_loss = epoch_train_loss + loss.item()\n      loss.backward()\n      optimizer.step()\n\n    epoch_train_loss = epoch_train_loss / (1.0 * len(train_loader))\n    train_loss.append(epoch_train_loss)\n    model.eval()\n    with torch.no_grad():\n      y_true_val = []\n      y_pred_val = []\n      epoch_val_loss = 0.0\n      epoch_val_acc = 0.0 \n      val_loader = DataLoader(val_dataset,batch_size=32)\n      for batch_id,batch in enumerate(val_loader):\n        inputs = {\"input_ids\": batch[0].to(device), \"attention_mask\": batch[1].to(device),  \"token_type_ids\": batch[2].to(device),\"labels\": batch[3].to(device)}\n        loss , logits = model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'],token_type_ids=inputs['token_type_ids'],labels=inputs['labels'])\n        epoch_val_loss = epoch_val_loss + loss.item()\n        _ , out_preds = torch.max(logits,axis=1)\n        epoch_val_acc =  epoch_val_acc + torch.eq(out_preds,inputs['labels'].squeeze(1)).sum().item()\n        #print(\"Validation id \",batch_id,batch[3].size(),torch.eq(out_preds,inputs['labels']).sum().item())\n        y_pred_val.extend(out_preds.detach().cpu().numpy().tolist())\n        y_true_val.extend(inputs[\"labels\"].squeeze(1).detach().cpu().numpy().tolist())\n\n      epoch_val_loss = epoch_val_loss / (len(val_loader)*1.0)\n      epoch_val_acc = epoch_val_acc / len(val_data)\n      val_loss.append(epoch_val_loss)\n      if best_loss > epoch_val_loss :\n        best_loss = epoch_val_loss\n        torch.save({\n                'model_state_dict':model.state_dict(),\n                'optimizer_state_dict':optimizer.state_dict(),\n                'loss':best_loss,},'/kaggle/saved_modelv1.pth')\n        \n    target_name = list(le.classes_)\n    print(\"*****************************************************************\")\n    print(\"Validation Report\")\n    print(\"*****************************************************************\")\n    print(classification_report(y_true_val,y_pred_val,target_names=target_name))\n    print(\"*****************************************************************\")\n  \n    print(epoch,train_loss[-1],val_loss[-1],epoch_val_acc,f1_score(y_true_val,y_pred_val,average='weighted'),accuracy_score(y_true_val,y_pred_val))  \n        \n  return model          ","execution_count":51,"outputs":[]},{"metadata":{"id":"3855n2aVNcRf"},"cell_type":"markdown","source":"## Tester Code"},{"metadata":{"id":"T7tb4oap-GmT","trusted":true},"cell_type":"code","source":"def test_engine(model,test_data):\n  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n  preds_all = []\n  true_all = []\n  test_loss = 0.0\n  test_acc = 0.0 \n  test_dataset = CreateData(tokenizer,test_data)\n  model.eval()\n  with torch.no_grad():\n      test_loader = DataLoader(test_dataset,batch_size=32)\n      for batch_id,batch in enumerate(test_loader):\n        inputs = {\"input_ids\": batch[0].to(device), \"attention_mask\": batch[1].to(device),  \"token_type_ids\": batch[2].to(device),\"labels\": batch[3].to(device)}\n        loss , logits = model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'],token_type_ids=inputs['token_type_ids'],labels=inputs['labels'])\n        test_loss = test_loss + loss.item()\n        _ , out_preds = torch.max(logits,axis=1)\n        test_acc =  test_acc + torch.eq(out_preds,inputs['labels'].squeeze(1)).sum().item()\n        preds_all.extend(out_preds.detach().cpu().numpy().tolist())\n        true_all.extend(inputs['labels'].squeeze(1).detach().cpu().numpy().tolist())\n\n      test_acc = test_acc / (len(test_data)*1.0)\n      tes_loss = test_loss / (1.0*len(test_loader))\n  return preds_all,true_all,test_loss,test_acc","execution_count":52,"outputs":[]},{"metadata":{"id":"5svPrMqpEY90"},"cell_type":"markdown","source":"### Check Sequence Length for Choosing Seq Length"},{"metadata":{"id":"PPi2Cy4g_DGz","outputId":"d5974ed9-65f0-42a2-9372-1dfc6697eb79","trusted":false},"cell_type":"code","source":"'''\nseq_len = []\nfor i in range(len(train)):\n  text = train.iloc[i][\"text\"]\n  temp = tokenizer.encode_plus(text)\n  seq_len.append(len(temp[\"input_ids\"]))\n\nprint(np.mean(seq_len))\n'''","execution_count":0,"outputs":[]},{"metadata":{"id":"vY7L8xIDVfux"},"cell_type":"markdown","source":"## Define the Model"},{"metadata":{"id":"qjq3NLuvV2JC","trusted":true},"cell_type":"code","source":"class XLNetClassifier(torch.nn.Module):\n  def __init__(self,labels):\n    super(XLNetClassifier,self).__init__()\n    #self.num_labels = labels\n    #self.config = config\n    self.xlnet_encoder = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',max_length=100,output_hidden_states=True,summary_type = \"mean\",_num_labels=labels)\n  \n  def forward(self,input_ids,token_type_ids,attention_mask,labels):\n    out = self.xlnet_encoder(input_ids=input_ids,token_type_ids=token_type_ids,\n                             attention_mask=attention_mask,labels=labels)\n    loss , logits = out[:2]\n    return (loss,logits)","execution_count":30,"outputs":[]},{"metadata":{"id":"mM-iSJ5DNXKA"},"cell_type":"markdown","source":"## Starter Code"},{"metadata":{"id":"BFUgmahadR8z","trusted":true},"cell_type":"code","source":"def main():\n  BATCH_SIZE = 16\n  LR = 2e-5\n  EPOCHS = 1\n  num_labels = len(Counter(train.target.values))\n  model = XLNetClassifier(num_labels)\n  #print(model.config)\n  model = train_engine(train,val,model.to(device),BATCH_SIZE,LR,EPOCHS,device)\n  model_best = XLNetClassifier(num_labels)\n  checkpoint = torch.load(\"/kaggle/saved_modelv1.pth\")\n  model_best.load_state_dict(checkpoint[\"model_state_dict\"])\n  model_best.to(device)\n  preds_all,true_all,test_loss,test_acc = test_engine(model_best,test)\n  target_name = list(le.classes_)\n  print(test_acc)\n  print(classification_report(true_all,preds_all,target_names=target_name))\n  pickle.dump(true_all,open(\"Test_True.p\",'wb'))\n  pickle.dump(preds_all,open(\"Test_Preds.p\",'wb'))","execution_count":54,"outputs":[]},{"metadata":{"id":"BIYtJe4nOBp9","trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\n","execution_count":55,"outputs":[]},{"metadata":{"id":"wsylITu1FN63","outputId":"f41bc0fd-c183-4660-c475-b0df2ace61c5","trusted":true},"cell_type":"code","source":"main()","execution_count":56,"outputs":[{"output_type":"stream","text":"0.9913181478715459\n                precision    recall  f1-score   support\n\n         Agent       1.00      0.99      0.99     44336\n        Device       0.96      1.00      0.98        88\n         Event       0.98      1.00      0.99      6765\n         Place       0.99      0.99      0.99     16282\n       Species       1.00      1.00      1.00      7787\n  SportsSeason       0.96      1.00      0.98      2077\nTopicalConcept       0.96      0.97      0.96       279\n    UnitOfWork       1.00      1.00      1.00       624\n          Work       0.99      0.99      0.99      7458\n\n      accuracy                           0.99     85696\n     macro avg       0.98      0.99      0.99     85696\n  weighted avg       0.99      0.99      0.99     85696\n\n","name":"stdout"}]},{"metadata":{"id":"ZY2PAXRCOwzo","outputId":"75811047-8c1c-40bf-d126-5043d5a2c517","trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]},{"metadata":{"id":"O9hIN9avOCcy","outputId":"8ac30aab-77a5-4d5d-bdf8-dbf0c01bf55e","trusted":false},"cell_type":"code","source":"# Some Basic Tests\nz = torch.tensor([[1,4],[3,7],[2,5]])\nz1 = torch.tensor([1,1,0])\nz = z.to(device)\n_ , preds = torch.max(z,axis=1)\nprint(z)\nprint(preds)\nprint(preds.detach().cpu())\nprint(preds)\ntorch.eq(preds,z1.to(device)).sum().item()","execution_count":0,"outputs":[]},{"metadata":{"id":"LPsEu_ESJgU0","trusted":false},"cell_type":"code","source":"\n1 2.218397746202519 1.7787151649263537 0.11122064440159676 2.2414355885923207 0.2325870646766169 0.05242849427672362","execution_count":0,"outputs":[]},{"metadata":{"id":"wo7jU9r8UmX6","trusted":false},"cell_type":"code","source":"config = XLNetConfig()\nconfig.from_pretrained = 'xlnet-base-cased'\nconfig.output_hidden_states = True\nconfig.output_attentions = False\nconfig.summary_type = 'mean'\n#config.n_layer = 12\n#config.n_head = 8\nconfig._num_labels = len(Counter(train.target.values))\nmodel = XLNetClassifier()\nmodel.xlnet_encoder.config.output_hidden_states = True\nmodel.xlnet_encoder.config.summary_type = \"mean\"","execution_count":0,"outputs":[]},{"metadata":{"id":"1lZ4dfaaUneN","trusted":false},"cell_type":"code","source":"tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')","execution_count":0,"outputs":[]},{"metadata":{"id":"ZLn46dLRFTE4","trusted":false},"cell_type":"code","source":"Input_ids = tokenizer.encode_plus(\"Hello, my dog is cute\", add_special_tokens=True)  # Batch size 1\ninput_ids , atten_mask , token_type_ids, labels  = torch.tensor(Input_ids[\"input_ids\"]).unsqueeze(0), torch.tensor(Input_ids[\"attention_mask\"]).unsqueeze(0),torch.tensor(Input_ids[\"token_type_ids\"]).unsqueeze(0),torch.tensor([1]).unsqueeze(0) ","execution_count":0,"outputs":[]},{"metadata":{"id":"viIqDZfv7Nj7","outputId":"0fc66596-8c22-43cd-d534-09fc298695c5","trusted":false},"cell_type":"code","source":"outputs = model(input_ids=input_ids,attention_mask=atten_mask,token_type_ids=token_type_ids,labels=labels)","execution_count":0,"outputs":[]},{"metadata":{"id":"9L-5dRvU7fRB","outputId":"370c97f8-6c93-4ae1-f96f-51b3710384e5","trusted":false},"cell_type":"code","source":"for z in model.xlnet_encoder.modules():\n  print(z)","execution_count":0,"outputs":[]},{"metadata":{"id":"k1KEweE48L_z","outputId":"40b2f0d1-4130-4f63-87e5-4c3840edfd34","trusted":true},"cell_type":"code","source":"t1= torch.tensor([0,1,3,2])\nt2 = torch.tensor([1,0,3,2])","execution_count":41,"outputs":[]},{"metadata":{"id":"RBJ2xv9k8Oxo","outputId":"11757bb3-8edb-4137-fe8b-dd3f27210031","trusted":true},"cell_type":"code","source":"t2 = t2.view(4,-1)","execution_count":42,"outputs":[]},{"metadata":{"id":"cSqkLxjeIirV","outputId":"a9d5c141-e685-45d4-c42c-af02ab46c843","trusted":true},"cell_type":"code","source":"t2.shape","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"torch.Size([4, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.eq(t1,t2.squeeze(1))","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"tensor([False, False,  True,  True])"},"metadata":{}}]},{"metadata":{"id":"6fE9IMKLJNPZ","trusted":false},"cell_type":"code","source":"val_dataset = CreateData(tokenizer,val)\nval_loader = DataLoader(val_dataset,batch_size=32)","execution_count":0,"outputs":[]},{"metadata":{"id":"0DJFiL4efaaC","outputId":"b3435ae4-88ff-48b6-afa7-20a61aed3066","trusted":false},"cell_type":"code","source":"(torch.tensor([0,1,1,0,1],dtype=torch.long).sum()/5.0).item()","execution_count":0,"outputs":[]},{"metadata":{"id":"OYjahy4BffFU","trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"colab":{"name":"Testing XLNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}